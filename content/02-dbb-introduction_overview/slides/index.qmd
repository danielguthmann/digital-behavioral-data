---
title: "Einf√ºhrung & √úberblick"
title-slide-attributes:
  # data-background-image: ../../background_title-dimmed_red_light.png
  data-background-color: "#04316a"
subtitle: "Digital behavioral data ‚Äì Session 02"
author: 
  - name: Christoph Adrian 
    url: https://twitter.com/chrdrn
    affiliation: Lehrstuhl f√ºr Kommunikationswissenschaft
    affiliation-url: https://www.kowi.rw.fau.de/person/christoph-adrian/
date: 02 11 2022
date-format: "DD.MM.YYYY"
format:
  revealjs:
    theme: ../../slidetheme.scss
    template-partials:
      - title-slide.html
    slide-number: true
    chalkboard:
      buttons: false
    preview-links: auto
    logo: ../../logo.png
    footer: "[Digital Behavioral Data](https://chrdrn.github.io/digital-behavioral-data/)"
comments:
  hypothesis: 
    theme: clean
filters:
  - roughnotation
execute:
  echo: true
bibliography: references.bib
csl: ../../apa.csl
---

## Seminarplan {.smaller}

| Sitzung                                              | Datum                                                         | Thema                                                               | Referent\*Innen                                                     |
|------------------|------------------|------------------|-------------------|
| [1]{.rn rn-type="strike-through" rn-color="#E6002E"} | [26.10.2022]{.rn rn-type="strike-through" rn-color="#E6002E"} | [Kick-Off Session]{.rn rn-type="strike-through" rn-color="#E6002E"} | [Christoph Adrian]{.rn rn-type="strike-through" rn-color="#E6002E"} |
| [**2**]{.rn rn-type="highlight"}                     | [**02.11.2022**]{.rn rn-type="highlight"}                     | [**DBD: Einf√ºhrung und √úberblick**]{.rn rn-type="highlight"}        | [**Christoph Adrian**]{.rn rn-type="highlight"}                     |
| 3                                                    | 09.11.2022                                                    | DBD: Datenerhebung                                                  | Christoph Adrian                                                    |
| 4                                                    | 16.11.2022                                                    | API-Access (I): *Twitter*                                           | Falk                                                                |
| 5                                                    | 23.11.2022                                                    | API-Access (II): *YouTube*                                          | Denisov                                                             |
| 6                                                    | 30.11.2022                                                    | API-Access (II): *Reddit*                                           | Landauer                                                            |
| 7                                                    | 07.12.2022                                                    | Webscraping: *TikTok*                                               | Brand & Kocher                                                      |
| 8                                                    | 14.12.2022                                                    | ESM: *m-path*                                                       | D√∂rr                                                                |
|                                                      |                                                               | *WEIHNACHTSPAUSE*                                                   |                                                                     |
| 9                                                    | 12.01.2023                                                    | Data Donations                                                      |                                                                     |
| 10                                                   | 19.01.2023                                                    | Mock-Up-Virtual Environments                                        |                                                                     |
| 11                                                   | 26.01.2023                                                    | Open Science                                                        |                                                                     |
| 12                                                   | 02.02.2023                                                    | ***Guest Lecture: Linking DBD & Survey data***                      | [Johannes Breuer](https://www.johannesbreuer.com/)                  |
| 13                                                   | 09.02.2023                                                    | Semesterabschluss & Evaluation                                      | Christoph Adrian                                                    |

::: notes
‚ñ∂Ô∏è
:::

# Agenda

1.  **Organisation und Koordination**

2.  **A short (re-)introduction to DBD**

3.  **Herausforderungen von DBD**

4.  **Wichtige Rahmenbedingungen von DBD**

5.  **Group Activity**

<!--# TODO: Folie √ºberarbeiten/Agenda aktualisieren -->

# Organisation & Koordination {background-color="#E6002E"}

Fragen, MS Teams & alternativer Seminarplan

## Kursmaterialien, Literatur etc.

#### Kurze Einf√ºhrung in Teams

![](images/ms_teams.png){fig-align="center"}

::: notes
-   Siehe: Webpage zum Kurs

-   Siehe: Syllabus
:::

## Vorschlag: Alternativer Seminarplan {.smaller}

| Sitzung         | Datum                                                     | Thema                                                                | Referent\*Innen                                     |
|------------------|------------------|------------------|-------------------|
| 1               | 26.10.2022                                                | Kick-Off Session                                                     | Christoph Adrian                                    |
| [2]{.smallcaps} | [02.11.2022]{.smallcaps}                                  | [DBD: Einf√ºhrung und √úberblick]{.smallcaps}                          | [Christoph Adrian]{.smallcaps}                      |
| 3               | 09.11.2022                                                | DBD: Datenerhebung                                                   | Christoph Adrian                                    |
| 4               | 16.11.2022                                                | API-Access (I): *Twitter*                                            | Falk                                                |
| 5               | 23.11.2022                                                | API-Access (II): *YouTube*                                           | Denisov                                             |
| 6               | 30.11.2022                                                | API-Access (II): *Reddit*                                            | Landauer                                            |
| 7               | 07.12.2022                                                | Webscraping: *TikTok*                                                | Brand & Kocher                                      |
| **8**           | [**14.12.2022**]{.rn rn-type="circle" rn-color="#E6002E"} | [**Exkurs: DBD Analyse mit R**]{.rn rn-type="box" rn-color="orange"} | **Christoph Adrian**                                |
|                 |                                                           | *WEIHNACHTSPAUSE*                                                    |                                                     |
| **9**           | [**12.01.2023**]{.rn rn-type="circle" rn-color="#E6002E"} | [**ESM: m-path**]{.rn rn-type="highlight"}                           | **D√∂rr**                                            |
| **10**          | [**19.01.2023**]{.rn rn-type="circle" rn-color="#E6002E"} | **TBD**                                                              | [**Hofmann & Wierzbicki**]{.rn rn-type="highlight"} |
| 11              | 26.01.2023                                                | Puffer                                                               |                                                     |
| 12              | 02.02.2023                                                | ***Guest Lecture: Linking DBD & Survey data***                       | [Johannes Breuer](https://www.johannesbreuer.com/)  |
| 13              | 09.02.2023                                                | Semesterabschluss & Evaluation                                       | Christoph Adrian                                    |

::: notes
‚ñ∂Ô∏è
:::

# A short (re-)introduction {background-color="#E6002E"}

Was sind *digital behavior data*?

Und *was* k√∂nnen wir mit Ihnen *untersuchen*?

## DBD -- Was ist das eigentlich?

#### R√ºckblick auf Definition nach @weller2021

-   ... fasst eine **Vielzahl von m√∂glichen Datenquellen** zusammen, die verschiedene Arten von **Aktivit√§ten aufzeichnen** (*h√§ufig sogar "nur" als Nebenprodukt*)

-   ... k√∂nnen dabei helfen, **Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien** zu erkennen

<br>

::: fragment
#### **Im Kontext dieses Seminars:**

-   Schwerpunkt: **Nutzung und Inhalte** von **soziale Medien**
-   **Computational Social Science** \[CSS\] **Verfahren**, z.B. zur Erhebung, Verarbeitung, Auswertung und Pr√§sentation
:::

## Ohne CSS keine DBD

#### Kurzer Exkurs zur Bedeutung von Computational Social Science

::: {.callout-important appearance="minimal"}
**Definition (Computational Social Science).**

We define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data." [@lazer2020]
:::

**hilft dabei ...**

-   genuine digitale Ph√§nomene zu untersuchen

-   digitale Verhaltensdaten zu sammeln und vorzuverarbeiten

-   neue Methoden zur Analyse von gro√üen Datens√§tzen anzuwenden

::: notes
CSS = neues Teilgebiet der Sozialwissenschaften oder neuer "Werkzeugkasten" zur Erg√§nzung der traditionellen sozialwissenschaftlichen Ans√§tze
:::

## Und was k√∂nnen wir damit untersuchen?

#### Beispiele f√ºr & Kategorisierung von untersuchbaren Verhalten & Interaktionen

::: columns
::: {.column width="65%"}
![Quelle: @keusch2021](images/dbd_matrix.png){fig-align="center" width="1024"}
:::

::: {.column width="35%"}
<br>

##### **Einschr√§nkungen**

-   Kategorisierung ist **Momentaufnahme** und nicht √ºberschneidungsfrei

-   **Selektive Nutzung** von bestimmten digitalen Ger√§ten bzw. Funktionen
:::
:::

::: notes
-   Kategorien: Digital/Analog individual/social behavior

-   Einige inh√§rent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)

-   Fehlen digitaler Spurendaten in all diesen Quadranten f√ºr bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Ger√§te.
:::

## Verf√ºgbarkeit als Pluspunkt

#### DBD als wertvolle Quelle bei aktuellen, sensiblen & unvorhersehbaren Themen

<br>

**Einsatz besonders Vorteilhaft bei Themen bzw. Untersuchungen ...**

-   ... f√ºr die es **schwierig** ist, Studienteilnehmer\*innen zu **rekrutieren**
-   ... bei denen **Beobachtungen** **vorteilhafter** sind als Befragungen

***Beispiel: Streaming und/oder Mining von Inhalten aus bestehenden digitalen Kommunikationsstr√∂men***

-   **Zeitnaher** als die Erstellung einer Umfrage
-   Zus√§tzlicher Nutzen als **Archiv** bei **unvorhersehbaren** **Ereignissen**

::: notes
üîî --\> Beispiele?

-   Meinung zu Corona auf Basis von Tweets

-   Well-being auf Basis von Instagram-Bildern & Texten
:::

## Mehr Daten durch technologischen Fortschritt

#### Beispiel: Wachsenden Anzahl eingebauter Smartphone-Sensoren

![Graphik aus @struminskaya2020](images/dbd_smartphone_development.jpeg){alt="Aus @struminskaya2020" fig-align="center"}

<!--# TODO: Bedeutung/Funktion der einzelnen Sensoren -->

## Eine kleine Lobeshymne auf DBD

#### Zwischenfazit

-   Digitale Ger√§te oder **Sensoren** k√∂nnen sich besser an bestimmte Fakten **besser "erinnern"** als das menschliche Ged√§chtnis.

-   Sensoren sind oft bereits **in allt√§gliche Technologie eingebaut** und produzieren digitale Verhaltensdaten als ein "Nebenprodukt".

-   Unaufdringliche Erfassung als potentieller Vorteil bzw. **Entlastung f√ºr Teilnehmer\*Innen**

-   **Kombination mit Umfragedaten** m√∂glich (und [bereichernd]{.rn rn-type="underline" rn-color="#E6002E"}!)

::: fragment
::: {.rn rn-type="box" rn-color="#E6002E"}
**Aber:**

Zur erfolgreichen Nutzung m√ºssen [Forschungsziele & verf√ºgbare Daten in Einklang]{.rn rn-type="highlight"} gebracht, m√∂gliche [Biases und methodische Probleme]{.rn rn-type="highlight"} ber√ºcksichttigt sowie die [Datenqualit√§t]{.rn rn-type="highlight"} evaluiert werden.
:::
:::

::: notes
‚ñ∂Ô∏è
:::

# Herausforderungen von DBD {background-color="#E6002E"}

Der Umgang mit Biases, methodischen T√ºcken und ethischen Einschr√§nkungen

## Wenn der Vorteil zum Nachteil wird

#### Ambivalenz der Unaufdringlichkeit [@keusch2021]

-   Unterscheidung zwischen **aufdringlichen** *(z.B. spezielle Research-App & Befragungen)* **& unaufdringlichen** *(z.B. Cookies, Browserplugins & APIs)* **erhobenen Daten**

-   **Bewertung** und Erwartung an Datensammlung ist **abh√§ngig vom Kontex**t (*z.B. Amazon vs. Researchgate*)

::: fragment
::: {.rn rn-type="box" rn-color="#E6002E"}
[**Dilema:**]{.rn rn-type="circle" rn-color="#E6002E"}

Einerseits bereitwillige (oft unwissende) [Abgabe]{.rn rn-type="highlight"} der Daten [an Konzerne]{.rn rn-type="highlight"}, andererseits h√§ufig [Bedenken]{.rn rn-type="highlight"} bez√ºglich Datenschutz & Privatsph√§re bei [wissenschaftlichen Studien]{.rn rn-type="highlight"}
:::
:::

::: notes
‚ñ∂Ô∏è \| üîî --\> Gr√ºnde f√ºr Ablehnung: Nutzenorientierung?
:::

## The End of Theory

::: {.fragment fragment-index="1"}
#### Zur Wichtigkeit von konzipierte Messungen & Designs
:::

> ["Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves." [@anderson2008]]{.rn rn-type="strike-through" rn-color="#E6002E" rn-multiline="true"}

::: {.fragment .semi-fade-out fragment-index="1"}
### Was denken Sie?
:::

::: {.fragment fragment-index="1"}
> "Size alone does [not]{.rn rn-type="underline" rn-color="#E6002E"} necessarily make the data better" [@boyd2007]

> "There are a lot of small data problems that occur in big data \[which\] don't disappear because you've got lots of the stuff. [They get worse.]{.rn rn-type="underline" rn-color="#E6002E"}" [@harford2014]
:::

::: notes
‚ñ∂Ô∏è \| üîî
:::

## We need to talk about [biases]{.smallcaps}

#### Spezifische und allgemeine Herausfoderungen f√ºr die Forschung mit DBD

**Hintergrund**: (*Big) Data ist zunehmend Grundlage f√ºr politische Ma√ünahmen, die Gestaltung von Produkten und Dienstleistungen und f√ºr die automatisierte Entscheidungsfindungr*

-   **Herausforderungen in Bezug auf DBD-Forschung:** fehlender Konsens √ºber ein Vokabular oder eine Taxonomie, h√§ufig nur impliziter Bezug in der Forschung

-   **Generelle Herausforderung:** [bias]{.rn rn-type="box" rn-color="#e6002e"} ist ein weit gefasster & in unterschiedlichen Disziplinen genutzter Begriff\

::: notes
‚ñ∂Ô∏è

"bias" hier im statistischen Sinne

Punkt2:

-   *conformation bias* und andere kognitive Voreingenommenheiten (Croskerry, 2002)

-   systemische, diskriminierende Ergebnisse (Friedman und Nissenbaum, 1996)

-   systemische Sch√§den (Barocas et al., 2017)
:::

<!--# Was bedeuten hier "systematische Sch√§de"-->

## Know your bias!

#### Framework zur Minimierung von Fehlern und Problemen [@olteanu2019]

![](images/bias_framework_without_legend.png){fig-align="center"}

::: notes
Beschreibung:

-   Die Analyse sozialer Daten beginnt mit bestimmten Zielen (Abschnitt 2.1), wie dem Verst√§ndnis oder der Beeinflussung von Ph√§nomenen, die f√ºr soziale Plattformen spezifisch sind (Typ I) und/oder von Ph√§nomenen, die √ºber soziale Plattformen hinausgehen (Typ II).

-   Diese Ziele erfordern, dass die Forschung bestimmte Validit√§tskriterien erf√ºllt, die weiter oben beschrieben wurden (Abschnitt 2.2).

-   Diese Kriterien k√∂nnen ihrerseits durch eine Reihe von allgemeinen Verzerrungen und Problemen beeintr√§chtigt werden (Abschnitt 3).

-   Diese Herausforderungen k√∂nnen von den Merkmalen der einzelnen Datenplattformen (Abschnitt 4) abh√§ngen - die oft nicht unter der Kontrolle des Forschers stehen - und von den Entscheidungen des Forschungsdesigns entlang einer Datenverarbeitungspipeline (Abschnitte 5 bis 8) - die oft unter der Kontrolle des Forschers stehen.

-   Pfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken
:::

## Worauf wirkt die Verzerrung?

#### Beispiele f√ºr Forschung von Typ I & II [@olteanu2019]

![](images/bias_framework_without_legend_v1.png){fig-align="center"}

::: notes
**Typ I: understand/influence phenomena [specific]{.underline} to social platforms**

-   Dynamik der Verbreitung von "Memes"
-   Steigerung der Attraktivit√§t bzw. besonders Features
-   Verbesserung der Suchfunktion oder des Empfehlungssystems

**Typ II: understand/influence phenomena [beyond]{.underline} social platforms**

-   Beschreibung des Einflusses sozialer Medien auf eine politische Wahl.

-   Nutzung sozialer Daten zur Verfolgung der Entwicklung ansteckender Krankheiten durch Analyse der von Social-Media-Nutzern online gemeldeten Symptomen
:::

## Zu welchen Problemen f√ºhren verschiedene Biases?

#### Einfl√ºsse von Biases auf Datenqualit√§t

![](images/bias_framework_without_legend_v2.png){fig-align="center"}

::: notes
-   Um diese Probleme in das umfassendere Konzept der Datenqualit√§t einzuordnen, geben wir zun√§chst einen kurzen √úberblick √ºber bekannte Probleme der Datenqualit√§t.

-   **Datenqualit√§t** ist ein vielschichtiges Konzept, typische Elemente sind *Genauigkeit, Vollst√§ndigkeit, Konsistenz, Aktualit√§t* und *Zug√§nglichkeit.*
:::

## Datenqualit√§t & *data bias* {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Data bias).**

A systematic distortion in the sampled data that compromises its representativeness**.**
:::

##### **Potentielle Probleme**

-   ***Sparsity:*** H√§ufig *Heavy-Tail*-Verteilung, was Analyse am "Kopf" (in Bezug auf h√§ufige Elemente oder Ph√§nomene) erleichtert, am "Schwanz" (wie seltene Elemente oder Ph√§nomene) jedoch erschwert (Baeza-Yates, 2013***).***

-   ***Noise:*** Unvollst√§ndige, besch√§digte, unzuverl√§ssige oder unglaubw√ºrdige Inhalte (Naveed et al., 2011; Boyd und Crawford, 2012).

    -   Unterscheidung von "Noise" und "Signal" ist oft unklar und h√§ngt von der Forschungsfrage ab (Salganik, 2017)

-   ***Organische vs gemessene Daten:*** Fragen zur Repr√§sentativit√§t (vs. Stichprobenbeschreibung), Kausalit√§t (vs. Korrelation) und Vorhersageg√ºte

## Im Fokus: Population Bias {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Population biases).**

Systematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.
:::

##### Potentielle Probleme

-   **Unterschiedliche Demographien** (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu **unterschiedlichen sozialen Plattformen**[^1] und nutzen deren **Mechanismen**[^2] unterschiedlich

-   **Proxies** f√ºr Eigenschaften oder demografische Kriterien der Nutzenden sind **unterschiedlich** **verl√§sslich**[^3]

[^1]: *Signifikant mehr Twitter-Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Nutzerinnen √ºberrepr√§sentiert (Ottoni et al., 2013)*

[^2]: *Unterschiedliche Twitter-Nutzung in Deutschland (Fokus auf Hashtags) und Korea (Fokus auf Konversationen) (Hong et al., 2011)*

[^3]: *Angabe √ºber Alumni-Status einer bestimmten Gruppe von Universit√§ten als Quelle f√ºr Verzerrung bei Meinung junger Hochschulabsolvent\*Innen zu einem neuen Gesetz (Ruths und Pfeffer, 2014)*

::: notes
H√§ufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.

Beispiel "Auswirkungen"

-   kann die (Stichproben)-Repr√§sentativit√§t beeintr√§chtigen\
    ‚û• ‚ö†Ô∏èexterne Validit√§t
-   besonders problematisch f√ºr Forschungsarbeiten des Typs II
-   kann sich auch auf die Leistung von Algorithmen auswirken, die R√ºckschl√ºsse auf die Nutzer ziehen\
    ‚û• ‚ö†Ô∏èinterne Validit√§t (Typ-I & Typ II)
    -   Sch√§tzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)
:::

## Im Fokus: Behavioral Biases {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Behavioral biases).**

Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.
:::

##### Potentielle Probleme

-   Beeinflussung der **Art und Weise**, wie Nutzer\*Innen miteinander **interagieren**[^4]

-   Auftreten von **Selbstselektion**[^5] und **Reaktionsverzerrungen**[^6][^7]

[^4]: *Interaktionsmuster viel sp√§rlicher als explizit erstellte soziale Verbindungen (20 % der Verbindungen haben 80 % der Interaktionen) (Wilson et al., 2009)*

[^5]: *Passivit√§t trotz Interesse an bestimmten Themen (Gong et al., 2016), aber: Aktivit√§t nicht sichtbar oder Selbstzensur (Wang et al., 2011; Das und Kramer, 2013; Matias et al., 2015)?*

[^6]: *Nutzer\*Innen reden eher √ºber extreme oder positive Erfahrungen als √ºber gew√∂hnliche oder negative Erfahrungen (K√≠c√≠man, 2012; Guerra et al., 2014). (response bias)*

[^7]: *75 % der Foursquare-Check-ins stimmen nicht mit der tats√§chlichen Mobilit√§t der Nutzer √ºbereinstimmen (Zhang et al., 2013)*

::: notes
Unterschiede in Bezug auf Nutzerpers√∂nlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)

##### Auswirkungen:

-   Ergebnisse einer Studie von der gew√§hlten Plattform oder dem Kontext abh√§ngig\
    ‚û§ ‚ö†Ô∏èexterne Validit√§t

-   nur Teilweise von population bias abh√§ngig

-   bei (expliziten oder impliziten) Annahmen √ºber die Verhaltensmuster der Nutzenden\
    ‚û§ ‚ö†Ô∏èpotentielle Effekte auf Untersuchung von Typ-I & Typ II (z.B. Untersuchung der Bed√ºrfnisse oder Interessen der Nutzenden)

Beispiel "Probleme":

-   Gesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken ("content production bias") und solche, die sich auf die Verkn√ºpfungsmuster zwischen Nutzern auswirken ("linking bias").

-   Drei weitere h√§ufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu f√ºhren, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden.
:::

## Im Fokus: Content Production Biases {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Content Production Biases)**

Behavioral biases that are expressed as lexical, syntactic, semantic, and structural differences in the content generated by users.
:::

##### Potentielle Probleme:

-   Der **Gebrauch der Sprache(n)** variiert zwischen und innerhalb von L√§ndern und Bev√∂lkerungsgruppen.[^8]

-   **Kontextbedingte Faktore**n (z.B. zwischenmenschliche Beziehungen) beeinflussen die Art und Weise, wie Benutzer sprechen.[^9]

-   Die Inhalte von **bekannten oder "erfahrenen" Nutzer*innen***unterscheiden sich von denen der normalen Nutzer\*innen.[^10]

-   **Unterschiedliche Bev√∂lkerungsgruppen** haben unterschiedliche **Neigungen**, √ºber bestimmte **Themen** zu sprechen.[^11]

[^8]: *Saisonale Schwankungen in der sprachlichen Zusammensetzung zwischen verschiedenen Gebiete (L√§nder, Regionen, Nachbarschaften etc.) (Mocanu et al., 2013)*

[^9]: *M√ºtter und V√§ter verwenden auf Facebook jeweils unterschiedliche Ansprache f√ºr T√∂chter & S√∂hne, und umgekehrt. (Burke et al., 2013)*

[^10]: *"Experten"-Nutzer auf Twitter neigen dazu, haupts√§chlich Inhalte zu ihrem Fachgebiet zu erstellen (Bhattacharya et al., 2014)*

[^11]: *Diaz et al. (2016) bei der Auswahl politischer Tweets w√§hrend der US-Wahlen 2012 fest, dass die Nutzerpopulation eher auf Washington, DC, ausgerichtet war, w√§hrend Olteanu et al. (2016) feststellten, dass Afroamerikaner eher den Twitter-Hashtag #BlackLivesMatter (√ºber eine gro√üe Bewegung zur Rassengleichheit in den USA) verwendeten.*

::: notes
Unterschiede bei nutzergenerierten Inhalten, insbesondere bei Texten, zwischen und innerhalb von demografischen Gruppen

Beispiel 1: Sprachgebrauchsvariationen je nach Geschlecht, Alter, regionaler Herkunft und politischer Orientierung auf Twitter (Rao et al. (2010)), sowie zwischen ethnischen Gruppen (Blodgett et al., 2016).

Beispiel 2: Au√üerdem zeigen Schwartz et al. (2015), dass die zeitliche Ausrichtung von Botschaften (Betonung der Vergangenheit, Gegenwart oder Zukunft) von Faktoren wie Offenheit f√ºr neue Erfahrungen, Anzahl der Freunde, Lebenszufriedenheit oder Depression beeinflusst werden kann.

Beispiel 3: Zafar et al. (2015) zeigen, wie die Konzentration der Stichprobe von Inhalten auf "Experten"-Nutzer die resultierende Stichprobe in Richtung vertrauensw√ºrdigerer und hochwertigerer Inhalte verzerrt.
:::

## Im Fokus: Linking Bias {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Linking Bias)**

Behavioral biases that are expressed as differences in the attributes of networks obtained from user connections, interactions or activity.
:::

##### Potentielle Probleme:

-   **Netzattribute**[^12][^13][^14] beeinflussen das Verhalten und die Wahrnehmung der Nutzer und umgekehrt

-   **Verhaltensbasierte** und **verbindungsbasierte**[^15] soziale **Verbindungen** sind **unterschiedlich**.

-   Die Bildung sozialer Online-Netzwerke h√§ngt auch von **Faktoren**[^16][^17] au√üerhalb der sozialen Plattformen ab

[^12]: *Anzahl der Follower der Nutzer\*Innen (Kƒ±cƒ±man, 2010)*

[^13]: *Altersspezifische Distanzen in sozialen Netzwerken (Dong et al., 2016)*

[^14]: *Homophilie - die Tendenz √§hnlicher Menschen, miteinander zu interagieren und sich zu verbinden (McPherson et al., 2001)*

[^15]: *Auf expliziten Verbindungen basierende Netzwerk deutlich dichter war als das auf Nutzerinteraktionen basierende (Wilson et al., 2009)*

[^16]: *Geografie (Poblete et al., 2011; Scellato et al., 2011)*

[^17]: *Art und die Dynamik der Offline-Beziehungen die Neigung der Nutzer, soziale Bindungen einzugehen und online zu interagieren (Subrahmanyam et al., 2008; Gilbert und Karahalios, 2009).*

::: notes
-   Sozialen Netzwerke, die aus beobachteten Mustern in Datens√§tzen (re)konstruiert werden, k√∂nnen sich grundlegend von den zugrunde liegenden (Offline-)Netzwerken unterscheiden (Schoenebeck, 2013a)\
    ‚û§ ‚ö†Ô∏èexterne Validit√§t ‚û§ ‚ö†Ô∏è Typ-II & teilweise Typ-I (F√§lle, in denen die Interaktions- oder Verkn√ºpfungsmuster der Nutzer mit der Zeit oder dem Kontext variieren)

-   wirken sich beispielsweise auf die Untersuchung der Struktur und Entwicklung sozialer Netzwerke, des sozialen Einflusses und von Ph√§nomenen der Informationsverbreitung aus (Wilson et al., 2009; Cha et al., 2010; Bakshy et al., 2012)

-   Auf sozialen Plattformen k√∂nnen sie auch zu systematisch verzerrten Wahrnehmungen √ºber Nutzer oder Inhalte f√ºhren (Lerman et al., 2016).
:::

## Im Fokus: Temporal Biases {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Temporal Biases)**

Systematic distortions across user populations or behaviors over time.
:::

##### Potentielle Probleme:

-   Bev√∂lkerungsgruppen, Verhaltensweisen[^18] und Systeme v**er√§ndern sich mit der Zeit**[^19].

-   **Saisonale** und **periodische** **Ph√§nomene**[^20][^21].

-   **Pl√∂tzlich** **auftretende Ph√§nomene** *(z.B. Anstieg oder R√ºckgang von besteimmten Aktivit√§ten*[^22] oder externe Ereignisse wie z.B. Katastrophen) wirken sich auf Populationen, Verhaltensweisen und Plattformen aus.

-   Die **zeitliche Granularit√§t** kann zu **feink√∂rnig** sein, um langfristige Ph√§nomene zu beobachten, und zu **grobk√∂rnig** sein, um kurzlebige Ph√§nomene zu beobachten.

-   **Datens√§tze verfallen** und verlieren mit der Zeit an Nutzen[^23].

[^18]: *Schwankungen in Bezug darauf, wann und wie lange sich die Nutzer\*Innen auf bestimmte Themen konzentrieren, was durch aktuelle Trends, saisonale oder periodische Aktivit√§ten oder sogar durch L√§rm ausgel√∂st werden kann (Radinsky et al., 2012).*

[^19]: *Drei Arten von zeitlichen Schwankungen: Populationsdrift, Verhaltensdrift und Systemdrift.(Salganik, 2017)*

[^20]: *Unterschiedliche zeitliche Kontexte (Tag vs. Nacht, Wochentag vs. Wochenende) ver√§ndert die Form der abgeleiteten Nachbarschaftsgrenzen eografisch verorteter Tweets (Kƒ±cƒ±man et al., 2014).*

[^21]: *Zusammenh√§nge zwischen der Stimmung von Tweets und Schlafzyklen und Saisonalit√§t (Golder und Macy, 2011)*

[^22]: *Einf√ºhrung einer neuen Plattformfunktion resutliert in pl√∂tzlichen Anstieg der Aktivit√§t (Malik und Pfeffer, 2016)*

[^23]: *Nutzer ihre Inhalte und Konten l√∂schen (Liu et al., 2014; Gillespie, 2015)*

::: notes
Auswirkunge:

-   ‚û§ ‚ö†Ô∏è eterne Validit√§t

-   Beeintr√§chtigen Verallgemeinerbarkeit von Beobachtungen im Laufe der Zeit ‚û§ ‚ö†Ô∏è Typ-I & Typ-II-Forschung problematisch

Probleme:

-   Die Art und Weise, wie man Datens√§tze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden k√∂nnen.
:::

## Im Fokus: Redundancy {.smaller}

::: {.callout-important appearance="minimal"}
**Definition (Redundancy)**

Single data items that appear in the data in multiple copies, which can be identical (duplicates), or almost identical (near duplicates).
:::

##### Potentielle Probleme:

-   **Lexikalische** (z. B. Duplikate, erneute Tweets, erneut geteilte Inhalte) und **semantische** (z. B. Beinahe-Duplikate oder dieselbe Bedeutung, aber anders geschrieben) **Redundanz** macht oft einen **erheblichen Teil der Inhalte aus** und kann sowohl **innerhalb als auch zwischen** Datens√§tzen auftreten.
-   Weitere Quellen f√ºr inhaltliche Redundanz sind h√§ufig **nicht-menschliche Konten,** wie z.B.
    -   ein und dieselbe **Person**, die **von mehreren Konten oder Plattformen** aus postet (z. B. Spam),

    -   **mehrere Nutzer**, die vom **selben Kont**o aus posten (z. B. Konten von Organisationen),

    -   **mehrere Personen, die denselben Inhalt posten** oder erneut posten (z. B. das Posten von Zitaten, Memes oder anderen Arten von Inhalten).

::: notes
Auswirkunge:

-   Redundanz kann, wenn sie nicht ber√ºcksichtigt wird, sowohl die interne als auch die √∂kologische/externe Validit√§t der Forschung beeintr√§chtigen, und zwar sowohl in der Forschung vom Typ I als auch vom Typ II (Abschnitt 2.1). Sie kann sich negativ auf den Nutzen von Instrumenten auswirken (Radlinski et al., 2011) und die Quantifizierung von Ph√§nomenen in den Daten verzerren.

Probleme:

-   Die Art und Weise, wie man Datens√§tze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden k√∂nnen.
-   Dies kann manchmal die Ergebnisse verzerren, aber Redundanz kann auch ein Signal an sich sein, z. B. kann das erneute Posten ein Signal f√ºr Wichtigkeit sein.
:::

## Sneak Preview in die n√§chste Sitzung

#### Datenerhebung im Fokus

![](images/bias_framework_without_legend_v3.png){fig-align="center"}

::: notes
-   Um diese Probleme in das umfassendere Konzept der Datenqualit√§t einzuordnen, geben wir zun√§chst einen kurzen √úberblick √ºber bekannte Probleme der Datenqualit√§t.

-   **Datenqualit√§t** ist ein vielschichtiges Konzept, typische Elemente sind *Genauigkeit, Vollst√§ndigkeit, Konsistenz, Aktualit√§t* und *Zug√§nglichkeit.*
:::

<!--# Obere Box markieren/hervorheben! -->

# Wichtige Rahmenbedingungen von DBD {background-color="#E6002E"}

Ethik & Recht im Fokus

## Erweiterung des Blickwinkels {.smaller}

#### Ethische Erw√§gungen bei DBD-Forschung

**Aus √∂ffentlicher Zug√§nglich- bzw. Verf√ºgbarkeit von Daten leitet sich nicht automatisch ethische Verwertbarkeit ab** [@zimmer2010; @boyd2012]

-   Verletzung der Privatsph√§re der Nutzer [@goroff2015]

-   Erm√∂glichung von rassischem, sozio√∂konomischem oder geschlechtsspezifischem Profiling [@barocas2016]

##### **Negative Beispiele**

-   **Facebook contagion experiment (**2012-2014): Feeds von Nutzer\*Innen so manipulierten, dass sie je nach den ge√§u√üerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten [@kramer2014]

-   **Encore-Forschungsprojekt**: Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen [@burnett2014]

::: notes
Hintergrund:

-   Ethische Fragen bisher epistemische Bedenken (Verwendung von nicht schl√ºssigen oder fehlgeleiteten Beweisen), jetzt normativ Bedenken (Folgen der Forschung)
-   Forschung grunds√§tzlich in vielen L√§ndern gesetztlich geregelt

Negativbeispiele:

-   Facebook contagion experiment: Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a).

-   Encore-Forschngsprojekt: Menschen in einigen L√§ndern durch diese Zugriffsversuche m√∂glicherweise gef√§hrdet wurden

Folgende Abschnitte:

-   zentrales Spannungsverh√§ltnis in der Forschungsethik digitaler Daten dargestellt.

-   Anschlie√üend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohlt√§tigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4).
:::

## Ein schmaler Grat

#### Forschungethik bei digitalen Daten

**Hintergrund**: *Die Herausforderung besteht in der Kombination von zwei extremen Sichtweisen, der Betrachtung der Forschung mit sozialen Daten als "klinische" Forschung oder als Computerforschung*

-   Die Sozialdatenforschung **unterscheidet sich von klinischen Versuchen**.

-   **Ethische Entscheidungen** in der Sozialdatenforschung m√ºssen **gut √ºberlegt sein**, da oft sind mehrere Werte betroffen, die miteinander in Konflikt stehen k√∂nnen

::: notes
Hintergrund:

1.  Die Sozialdatenforschung √§hnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer F√§higkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden

2.  die Sozialdatenforschung √§hnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.

Punkt 2: Sch√§den, die die √ºblichen Arten der Sozialdatenforschung ( z. B. die Verletzung der Privatsph√§re oder der Anblick verst√∂render Bilder)verursachen k√∂nnen, oft nicht mit Sch√§den von klinischen Versuchen gleichzusetzen

Punkt 3: Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten L√∂sungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015).
:::

## Achtung der individuellen Autonomie {.smaller}

#### Diskussion der Informierte Zustimmung als Indikator autonomer Entscheidung

**Die Einwilligung nach Aufkl√§rung setzt voraus, dass**

1.  die Forscher\*Innen den potenziellen Teilnehmenden alle **relevanten Informationen offenlegen**;
2.  die potenziellen Teilnehmenden **in der Lage** sind, diese **Informationen zu bewerten;**
3.  die potenziellen Teilnehmenden **freiwillig entscheiden** k√∂nnen, ob sie **teilnehmen** wollen oder nicht;
4.  die Teilnehmenden den Forschernden ihre **ausdr√ºckliche Erlaubnis erteilen**, h√§ufig in schriftlicher Form; und
5.  die Teilnehmende die M√∂glichkeit haben, ihre **Einwilligung jederzeit zur√ºckzuziehen**.

<br>

##### **Potentielle Probleme**

-   Die **Zustimmung** von **Millionen** von Nutzern einzuholen ist **unpraktisch**.

-   Das **√∂ffentliche Teilen** von Inhalten im Internet **bedeutet nicht** unbedingt eine **Zustimmung** zur Forschung[^24].

-   Die **Nutzungsbedingungen** sozialer Plattformen stellen m√∂glicherweise **keine informierte Zustimmung** zur Forschung dar.

[^24]: Datenschutzpr√§ferenzen h√§ngen h√§ufig von Lebensumst√§nden ab (Crawford und Finn, 2014)

::: notes
Beispiel 1:

-   H√§ufig keine Zustimmung bei Studien mit Daten von Millionen von Social-Media-Nutzern (Zimmer, 2010; Hutton und Henderson, 2015a)

-   Obwohl die Einholung der Zustimmung oft als unpraktisch angesehen wird (Boyd und Crawford, 2012), gibt es Bem√ºhungen, Methoden zur Einholung der Zustimmung zu entwickeln, die den Aufwand f√ºr die Teilnehmer m√∂glichst gering halten (Hutton und Henderson, 2015a).
:::

## Wohlt√§tigkeit und Unsch√§dlichkeit als Ziel {.smaller}

#### Bewertung von Risken & Nutzen

**Hintergrund**: *Nicht nur Fokus auf den Nutzen der Forschung, sondern auch auf die m√∂glichen Arten von Sch√§den, die betroffenen Gruppen und die Art und Weise, wie nachteilige Auswirkungen getestet werden k√∂nnen .*[@sweeney2013]

<br>

###### Potentielle Probleme

-   **Daten** √ºber **Einzelpersonen** k√∂nnen ihnen **schaden, wenn** sie **offengelegt** werden[^25][^26].

-   **Forschungsergebnisse** **k√∂nnen** verwendet werden, um **Schaden** anzurichten[^27].

-   **"Dual-Use"- und Sekund√§ranalysen** sind in der Sozialdatenforschung **immer** **h√§ufiger** anzutreffen[^28].

[^25]: Stalking, Diskriminierung, Erpressung oder Identit√§tsdiebstahl (Gross und Acquisti, 2005).

[^26]: Zu lange Archivierung personenbezogener Daten oder die √∂ffentliche Freigabe schlecht anonymisierter Datens√§tze kann zu Verletzungen der Privatsph√§re f√ºhren, da diese Daten mit anderen Quellen kombiniert werden k√∂nnen, um Erkenntnisse √ºber Personen ohne deren Wissen zu gewinnen (Crawford und Finn, 2014; Goroff, 2015; Horvitz und Mulligan, 2015)

[^27]: Abgesehen von der Tatsache, dass aus sozialen Daten gezogene R√ºckschl√ºsse in vielerlei Hinsicht falsch sein k√∂nnen, wie in dieser Studie hervorgehoben wird, k√∂nnen zu pr√§zise R√ºckschl√ºsse dazu f√ºhren, dass Menschen in immer kleinere Gruppen eingeteilt werden k√∂nnen (Barocas, 2014).

[^28]: Daten, Instrumente und Schlussfolgerungen, die f√ºr einen bestimmten Zweck gewonnen wurden, f√ºr einen anderen Zweck verwendet werden (Hovy und Spruit, 2016; Benton et al., 2017)

::: notes
Die Forschung zu sozialen Daten wird mit bestimmten Arten von Sch√§den in Verbindung gebracht, von denen die Verletzung der Privatsph√§re vielleicht die offensichtlichste ist (Zimmer, 2010; Crawford und Finn, 2014).

Beispiel 1: Einige prominente Beispiele sind die Datenpanne bei Ashley Madison im Jahr 2015, bei der einer Website, die sich als Dating-Netzwerk f√ºr betr√ºgerische Ehepartner anpreist, Kontoinformationen (einschlie√ülich der vollst√§ndigen Namen der Nutzer) gestohlen und online gestellt wurden (Thomsen, 2015), sowie die j√ºngsten Datenpannen bei Facebook, bei denen Hunderte Millionen von Datens√§tzen mit Kommentaren, Likes, Reaktionen, Kontonamen, App-Passw√∂rtern und mehr √∂ffentlich gemacht wurden.
:::

## Faire Verteilung von Risiken & Nutzen {.smaller}

#### Recht & Gerechtigkeit

**Annahme**: *Es ist von Anfang an bekannt, wer durch die Forschung belastet wird und wer von den Ergebnissen profitieren wird.*

<br>

###### Potentielle Probleme

-   Die **digitale Kluft** kann das Forschungsdesign beeinflussen[^29] (Stichwort: WEIRD Samples)

-   **Algorithmen** und Forschungsergebnisse k√∂nnen zu **Diskriminierung** f√ºhren.

-   **Forschungsergebnisse** sind m√∂glicherweise **nicht** allgemein **zug√§nglich[^30]**.

-   Nicht alle **Interessengruppen** werden √ºber die Verwendung von Forschungsergebnissen konsultiert[^31].

[^29]: Data divide: mangelnde Verf√ºgbarkeit von hochwertigen Daten √ºber Entwicklungsl√§nder und unterprivilegierte Gemeinschaften (Cinnamon und Schuurman, 2013).

[^30]: Idealerweise sollten die Menschen Zugang zu den Forschungsergebnissen und Artefakten haben, die aus der Untersuchung ihrer pers√∂nlichen Daten entstanden sind (Gross und Acquisti, 2005; Crawford und Finn, 2014).

[^31]: In die √úberlegungen dar√ºber, wie, f√ºr wen und wann Forschungsergebnisse umgesetzt werden, sollten diejenigen einbezogen werden, die m√∂glicherweise betroffen sind oder deren Daten verwendet werden (Costanza-Chock, 2018; Design Justice, 2018; Green, 2018)

::: notes
üîî-\> Plausibilit√§t der Annahme?
:::

## Zwei Trends, Drei Fragen, Vier Empfehlungen {.smaller}

#### Zusammenfassung und Ausblick

**Trend 1: Eine zunehmende Skepsis gegen√ºber einfachen Antworten**

1.  Wie einstehen die Daten, was enthalten sie tats√§chlich und wie die Arbeitsdatens√§tze zusammengestellt?

2.  Wird deutlich, was was ausgewertet wird?

3.  Wird die Verwendung von vorgefertigten Datens√§tzen und Modellen des maschinellen Lernens hinterfragt?

<br>

**Trend 2: Vom Aufwerfen von Bedenken √ºber soziale Daten zum Umgang mit ihnen. 4 Empfehlungen:**

1.  **Detaillierte Dokumentation** und kritische **Pr√ºfung** der Datensatz- und Modellerstellung

2.  DBD-Studien auf v**erschiedene Plattformen, Themen, Zeitpunkte und Teilpopulationen auszuweiten**, um festzustellen, wie sich die Ergebnisse beispielsweise in verschiedenen kulturellen, demografischen und verhaltensbezogenen Kontexten unterscheiden

3.  **Transparenzmechanismen** zu schaffen, die es erm√∂glichen, soziale Software zu √ºberpr√ºfen und Verzerrungen in sozialen Daten an der Quelle zu evaluieren

4.  **Forschung** zu diesen Leitlinien, Standards, Methoden und Protokollen **auszuweiten** und ihre √úbernahme zu f√∂rdern.

    ::: notes
    Schlie√ülich gibt es angesichts der Komplexit√§t der inh√§rent kontextabh√§ngigen, anwendungs- und bereichsabh√§ngigen Verzerrungen und Probleme in sozialen Daten und Analysepipelines, die in diesem Papier behandelt werden, keine Einheitsl√∂sungen - bei der Bewertung und Bek√§mpfung von Verzerrungen ist Nuancierung entscheidend.
    :::

# Group Activity

Gruppendiskussion

## Vielen Dank f√ºr Ihre Fragen!

# Bis zur n√§chsten Sitzung! {background-color="#04316a"}

## Literatur

::: {#refs}
:::
